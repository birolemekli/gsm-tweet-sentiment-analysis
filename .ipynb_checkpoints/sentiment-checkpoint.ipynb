{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers import  Embedding, SimpleRNN, LSTM,Masking,Bidirectional\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import model_from_json,model_from_yaml,load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence,text\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import metrics, regularizers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data yükleme, boş satıları silme, aynı satıları temizleme, silinen satırlardan dolayı bozulan indexsi yeniden yaratma\n",
    "X_train = pd.read_excel('./hepsi-X_train.xlsx')\n",
    "X_test=pd.read_excel('./hepsi-X_test.xlsx')\n",
    "y_train=pd.read_excel('./hepsi-y_train.xlsx')\n",
    "y_test=pd.read_excel('./hepsi-y_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[10:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model için gerekli değerler\n",
    "#epochs_sayisi=5\n",
    "batch_size=8\n",
    "# Çıktı gözükmemesi için\n",
    "verbose=1\n",
    "validation_split=0.1\n",
    "max_len=15\n",
    "vocab_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(epoch_sayisi):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,max_len, trainable=True,input_length=max_len))\n",
    "    model.add(SimpleRNN(32,activation='relu',kernel_regularizer=regularizers.l2(0.01),return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(16,activation='relu',kernel_regularizer=regularizers.l2(0.01),return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(4,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001), metrics=['acc'])\n",
    "    history=model.fit(X_train, y_train, epochs=epoch_sayisi, batch_size=batch_size,\n",
    "                      verbose=verbose,validation_split=validation_split)\n",
    "    return history,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(epoch_sayisi):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,max_len, trainable=True,input_length=max_len))\n",
    "    model.add(LSTM(32,activation='relu',kernel_regularizer=regularizers.l2(0.01),return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(16,activation='relu',kernel_regularizer=regularizers.l2(0.01),return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(4,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['acc'])\n",
    "    history=model.fit(X_train, y_train, epochs=epoch_sayisi, batch_size=batch_size,\n",
    "                      verbose=verbose,validation_split=validation_split)\n",
    "    return history,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(epoch_sayisi):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,max_len, trainable=True,input_length=max_len))\n",
    "    model.add(Conv1D(32,1,kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(16,1,kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(4,1,kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['acc'])\n",
    "    history=model.fit(X_train, y_train, epochs=epoch_sayisi, batch_size=batch_size,\n",
    "                      verbose=verbose,validation_split=validation_split)\n",
    "    return history,model\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(algoritma,model):\n",
    "    #Hiç eğitime sokulmamış veri ile test\n",
    "    test=model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"\\n\\nTest %s modelinde test %s: %.2f%% --- %s: %.2f%%\" % (algoritma,model.metrics_names[1], test[1]*100,model.metrics_names[0], test[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "curr_session = tf.get_default_session()\n",
    "if curr_session is not None:\n",
    "    curr_session.close()\n",
    "K.clear_session()\n",
    "s = tf.InteractiveSession()\n",
    "K.set_session(s)\n",
    "\n",
    "epoch_sayisi=int(input(\"Eposh sayisini giriniz..:\"))\n",
    "\n",
    "print('''\n",
    "    Uygulanacak algoritmayı seçiniz:\n",
    "    1 - CNN\n",
    "    2 - RNN\n",
    "    3 - LSTM\n",
    "    ''')\n",
    "\n",
    "algoritma=input(\"Seçim:\").lower()\n",
    "if(algoritma==\"cnn\"):\n",
    "    history,model=cnn(epoch_sayisi)\n",
    "elif(algoritma==\"rnn\"):\n",
    "    history,model=rnn(epoch_sayisi)\n",
    "elif(algoritma==\"lstm\"):\n",
    "    history,model=lstm(epoch_sayisi)\n",
    "\n",
    "print(\"**** %s modelinde %s epochluk Acc %.2f  Loss %.2f\" %(algoritma,epoch_sayisi,history.history['acc'][epoch_sayisi-1]*100,history.history['loss'][epoch_sayisi-1]*100))\n",
    "\n",
    "rnn_test=test(algoritma,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "epochs = range(1, epoch_sayisi+1)\n",
    "Acc = history.history['acc']\n",
    "Val_acc =history.history['val_acc']\n",
    "plt.plot(epochs, Acc, 'bo', label='Acc')\n",
    "plt.plot(epochs, Val_acc, 'b+', label='Vall Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='validation Loss')\n",
    "plt.title(algoritma.upper() + ' Regularization Loss Fonksiyonu')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.xlabel('Epoch Sayısı')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
